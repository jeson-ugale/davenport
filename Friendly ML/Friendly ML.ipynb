{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeson\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Type of learning:\n",
      "\n",
      " 1. supervised\n",
      " 2. unsupervised\n",
      "\n",
      " Enter the option number: 1\n",
      "----------------------------------------\n",
      "Type of supervised learning problem:\n",
      "\n",
      " 1. regression\n",
      " 2. classification\n",
      "\n",
      " Enter the option number: 1\n",
      "----------------------------------------\n",
      "\n",
      "Files currently in datasets folder:\n",
      "\n",
      "1. association_rule_practice.csv\n",
      "2. Churn_Modelling.csv\n",
      "3. classification_practice.csv\n",
      "4. clas_short.csv\n",
      "5. clustering_practice.csv\n",
      "6. regression_practice.csv\n",
      "7. reg_short.csv\n",
      "Name of .csv: 6\n",
      "\n",
      "Rows x Columns\n",
      "(399, 10)\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Potential Labels\n",
      "\n",
      "0. longitude\n",
      "1. latitude\n",
      "2. housing_median_age\n",
      "3. total_rooms\n",
      "4. total_bedrooms\n",
      "5. population\n",
      "6. households\n",
      "7. median_income\n",
      "8. median_house_value\n",
      "9. ocean_proximity\n",
      "Index of dependent variable: 8\n",
      "----------------------------------------\n",
      "\n",
      "Want to remove any features?\n",
      "\n",
      "0. longitude\n",
      "1. latitude\n",
      "2. housing_median_age\n",
      "3. total_rooms\n",
      "4. total_bedrooms\n",
      "5. population\n",
      "6. households\n",
      "7. median_income\n",
      "8. ocean_proximity\n",
      "Indices of unwanted features: 8\n",
      "----------------------------------------\n",
      "\n",
      "Feature Importances\n",
      "\n",
      "- 7. median_income: 0.4791405709026858\n",
      "- 1. latitude: 0.11043486989176557\n",
      "- 0. longitude: 0.10445311080279673\n",
      "- 2. housing_median_age: 0.0819968922057672\n",
      "- 5. population: 0.06195412203780456\n",
      "- 3. total_rooms: 0.06192697379965403\n",
      "- 4. total_bedrooms: 0.05548762983861254\n",
      "- 6. households: 0.04460583052091362\n",
      "Indices of features: 7,1,0,2\n",
      "Select regression algorithm:\n",
      "\n",
      " 1. linear regression\n",
      " 2. polynomial regression\n",
      " 3. support vector regression\n",
      " 4. decision tree regression\n",
      " 5. random forest regression\n",
      " 6. xgboost regression\n",
      "\n",
      " Enter the option number: *\n",
      "Automatic hyperparameter tuning? [y/n]: n\n",
      "----------------------------------------\n",
      "1.\n",
      "Here's the optimal Linear Regression model:\n",
      "\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "\n",
      "After training on your data, this model achieved an RMSE of 78842.87.\n",
      "On the test/unseen data, this model achieved an RMSE of 73333.88.\n",
      "It took 0.00 minutes to find this model.\n",
      "----------------------------------------\n",
      "2.\n",
      "Here's the optimal Polynomial Regression model:\n",
      "\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
      "\n",
      "After training on your data, this model achieved an RMSE of 80173.77.\n",
      "On the test/unseen data, this model achieved an RMSE of 81256.86.\n",
      "It took 0.00 minutes to find this model.\n",
      "----------------------------------------\n",
      "3.\n",
      "Here's the optimal SVM Regression model:\n",
      "\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "After training on your data, this model achieved an RMSE of 0.69.\n",
      "On the test/unseen data, this model achieved an RMSE of 231395.01.\n",
      "It took 0.00 minutes to find this model.\n",
      "----------------------------------------\n",
      "4.\n",
      "Here's the optimal Decision Tree Regression model:\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n",
      "\n",
      "After training on your data, this model achieved an RMSE of 99719.30.\n",
      "On the test/unseen data, this model achieved an RMSE of 89239.02.\n",
      "It took 0.00 minutes to find this model.\n",
      "----------------------------------------\n",
      "5.\n",
      "Here's the optimal Random Forest Regression model:\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "After training on your data, this model achieved an RMSE of 72959.76.\n",
      "On the test/unseen data, this model achieved an RMSE of 78386.70.\n",
      "It took 0.00 minutes to find this model.\n",
      "----------------------------------------\n",
      "6.\n",
      "Here's the optimal XGBoost Regression model:\n",
      "\n",
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "\n",
      "After training on your data, this model achieved an RMSE of 71291.88.\n",
      "On the test/unseen data, this model achieved an RMSE of 68682.15.\n",
      "It took 0.00 minutes to find this model.\n",
      "Enter the number of your chosen model: 6\n",
      "----------------------------------------\n",
      "Your XGBoost Regression model predicts the 'median_house_value' label.\n",
      "\n",
      "It takes in the 4 following features:\n",
      " \n",
      "1. median_income\n",
      "2. latitude\n",
      "3. longitude\n",
      "4. housing_median_age\n",
      "Predict the label for a new observation: 1,1,1,1\n",
      "\n",
      "Your model predicted the following 'median_house_value' label:\n",
      "\n",
      "[137716.33]\n",
      "----------------------------------------\n",
      "Your XGBoost Regression model predicts the 'median_house_value' label.\n",
      "\n",
      "It takes in the 4 following features:\n",
      " \n",
      "1. median_income\n",
      "2. latitude\n",
      "3. longitude\n",
      "4. housing_median_age\n",
      "Predict the label for a new observation: 1,2,3,4\n",
      "\n",
      "Your model predicted the following 'median_house_value' label:\n",
      "\n",
      "[137716.33]\n",
      "----------------------------------------\n",
      "Your XGBoost Regression model predicts the 'median_house_value' label.\n",
      "\n",
      "It takes in the 4 following features:\n",
      " \n",
      "1. median_income\n",
      "2. latitude\n",
      "3. longitude\n",
      "4. housing_median_age\n",
      "Predict the label for a new observation: 1.4, 100, -100, 253\n",
      "\n",
      "Your model predicted the following 'median_house_value' label:\n",
      "\n",
      "[34043.48]\n",
      "----------------------------------------\n",
      "Your XGBoost Regression model predicts the 'median_house_value' label.\n",
      "\n",
      "It takes in the 4 following features:\n",
      " \n",
      "1. median_income\n",
      "2. latitude\n",
      "3. longitude\n",
      "4. housing_median_age\n",
      "Predict the label for a new observation: quit\n"
     ]
    }
   ],
   "source": [
    "# %load Friendly ML.py\n",
    "\"\"\"\n",
    "Created on Sat Jan 26 18:19:20 2019\n",
    "\n",
    "@author: jeson\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    # Importing the libraries\n",
    "    import backend.backend as back\n",
    "    \n",
    "    # Request learning type\n",
    "    learning_type = back.request_learning()\n",
    "    \n",
    "    # Request problem\n",
    "    problem = back.request_problem(learning_type)\n",
    "    \n",
    "    # Request dataset/features/label. Encodes categorical variables.\n",
    "    data = back.request_all_data(problem)\n",
    "    \n",
    "    # Request model\n",
    "    model = back.request_model(problem, data)\n",
    "    \n",
    "    # Predict until user inputs 'quit'\n",
    "    back.predict_until_quit(data, model, problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
